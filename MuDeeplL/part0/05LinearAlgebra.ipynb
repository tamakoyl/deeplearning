{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "B = A.clone()# 另外开辟一块内存\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表示任意形状张量的元素和(丢掉维度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n"
     ]
    }
   ],
   "source": [
    "A.shape ,A.sum()#scalar\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.,  1.],\n",
       "          [ 2.,  3.],\n",
       "          [ 4.,  5.],\n",
       "          [ 6.,  7.],\n",
       "          [ 8.,  9.]],\n",
       " \n",
       "         [[10., 11.],\n",
       "          [12., 13.],\n",
       "          [14., 15.],\n",
       "          [16., 17.],\n",
       "          [18., 19.]]]),\n",
       " tensor([[10., 12.],\n",
       "         [14., 16.],\n",
       "         [18., 20.],\n",
       "         [22., 24.],\n",
       "         [26., 28.]]),\n",
       " torch.Size([5, 2]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = A.reshape(2,5,2)\n",
    "A_sum_axis0 = A.sum(axis=0)#最后长成剩下维度的shape\n",
    "A,A_sum_axis0,A_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[20., 25.],\n",
       "         [70., 75.]]),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis1 = A.sum(axis=1)#最后长成剩下维度的shape\n",
    "A_sum_axis1,A_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以按两个维度求和 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 90., 100.]), torch.Size([2]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis0_1 = A.sum(axis=[0,1])#最后长成剩下维度的shape\n",
    "A_sum_axis0_1,A_sum_axis0_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 平均值（mean或average）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9.5000), tensor(9.5000))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  6.],\n",
       "         [ 7.,  8.],\n",
       "         [ 9., 10.],\n",
       "         [11., 12.],\n",
       "         [13., 14.]]),\n",
       " tensor([[ 5.,  6.],\n",
       "         [ 7.,  8.],\n",
       "         [ 9., 10.],\n",
       "         [11., 12.],\n",
       "         [13., 14.]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算总和或均值时保持轴数不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.,  1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.,  9.]],\n",
       " \n",
       "         [[10., 11., 12., 13., 14.],\n",
       "          [15., 16., 17., 18., 19.]]]),\n",
       " tensor([[[ 5.,  7.,  9., 11., 13.]],\n",
       " \n",
       "         [[25., 27., 29., 31., 33.]]]),\n",
       " torch.Size([2, 1, 5]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = A.reshape(2,2,5)\n",
    "A_sum_1 = A.sum(axis=1,keepdims=True)\n",
    "A,A_sum_1,A_sum_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过广播将A除以sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.1429, 0.2222, 0.2727, 0.3077],\n",
       "         [1.0000, 0.8571, 0.7778, 0.7273, 0.6923]],\n",
       "\n",
       "        [[0.4000, 0.4074, 0.4138, 0.4194, 0.4242],\n",
       "         [0.6000, 0.5926, 0.5862, 0.5806, 0.5758]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / A_sum_1#方便做广播，因为广播要求维度要相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "某个轴计算A元素的累积总和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.]],\n",
       "\n",
       "        [[10., 12., 14., 16., 18.],\n",
       "         [20., 22., 24., 26., 28.]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 乘法\n",
    "- 向量dot点乘\n",
    "- mv(matrix and vector)\n",
    "- mm(matrix and matrix)\n",
    "- IL1 范数，它表示为向量元素的绝对值之和\n",
    "- 范数 L2范数是向量元素平方和的平方根\n",
    "- 矩阵 的弗罗贝尼乌斯范数（Frobenius norm）是矩阵元素平方和的平方根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DOT,仅限vectors\n",
    "x = torch.arange(4,dtype=torch.float32)\n",
    "y= torch.ones(4,dtype=torch.float32)\n",
    "x,y,torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1.]),\n",
       " tensor([[0., 1.],\n",
       "         [2., 3.],\n",
       "         [4., 5.],\n",
       "         [6., 7.]]),\n",
       " tensor([ 1.,  5.,  9., 13.]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix and vector\n",
    "x = torch.ones(2,dtype=torch.float32)\n",
    "A = torch.arange(8,dtype=torch.float32).reshape(4,2)\n",
    "x,A,torch.mv(A,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1.],\n",
       "         [2., 3.],\n",
       "         [4., 5.],\n",
       "         [6., 7.]]),\n",
       " tensor([[0., 1.],\n",
       "         [2., 3.],\n",
       "         [4., 5.],\n",
       "         [6., 7.]]),\n",
       " tensor([[ 1.,  3.,  5.,  7.],\n",
       "         [ 3., 13., 23., 33.],\n",
       "         [ 5., 23., 41., 59.],\n",
       "         [ 7., 33., 59., 85.]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = A\n",
    "A,B,torch.mm(A,B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1范数\n",
    "torch.abs(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 范数\n",
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵元素平方和的平方根\n",
    "torch.norm(torch.ones((4, 9)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e6dea04d1ee67d02776821fdeeb43d084fbfe2bd3d12fe23449057b6c79404a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
